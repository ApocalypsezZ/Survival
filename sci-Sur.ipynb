{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The raw_dataset has the following shape: (5073, 22).\n"
     ]
    },
    {
     "data": {
      "text/plain": "     ID  state       time  treatment_before  gender       age  Etiology  ECOG  \\\n0  5002      1  26.618056                 0       0  53.04783         1     0   \n1  5003      0  85.544444                 0       1  59.76347         1     0   \n2  5004      0   1.666573                 0       1  58.95445         1     0   \n3  5005      1  42.652778                 0       1  68.12717         1     0   \n4  5006      0  12.486111                 0       1  54.56005         1     0   \n\n   tumor_number  tumor_size  ...  TBIL         AST    ALT    PLT       INR  \\\n0             2        18.0  ...  22.9  161.000000  218.2  348.0  1.050000   \n1             2         4.0  ...  21.5   58.614578   23.4   37.0  1.155444   \n2             2         9.8  ...  28.1   95.000000  306.5  118.0  1.170000   \n3             2         4.1  ...  15.9   44.000000   13.8  115.0  1.260000   \n4             2         4.1  ...  34.5   24.000000   39.0  165.0  1.140000   \n\n        BUN         Cr    WBC    HGB  therapy  \n0  5.556726  47.000000   8.07   61.2     TACE  \n1  7.500000  87.000000  75.00  157.0     TACE  \n2  4.600000  52.300000  62.00  131.0     TACE  \n3  5.200000  73.088394  29.00  134.0     TACE  \n4  5.556726  73.088394  20.90  148.5     TACE  \n\n[5 rows x 22 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>state</th>\n      <th>time</th>\n      <th>treatment_before</th>\n      <th>gender</th>\n      <th>age</th>\n      <th>Etiology</th>\n      <th>ECOG</th>\n      <th>tumor_number</th>\n      <th>tumor_size</th>\n      <th>...</th>\n      <th>TBIL</th>\n      <th>AST</th>\n      <th>ALT</th>\n      <th>PLT</th>\n      <th>INR</th>\n      <th>BUN</th>\n      <th>Cr</th>\n      <th>WBC</th>\n      <th>HGB</th>\n      <th>therapy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5002</td>\n      <td>1</td>\n      <td>26.618056</td>\n      <td>0</td>\n      <td>0</td>\n      <td>53.04783</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>18.0</td>\n      <td>...</td>\n      <td>22.9</td>\n      <td>161.000000</td>\n      <td>218.2</td>\n      <td>348.0</td>\n      <td>1.050000</td>\n      <td>5.556726</td>\n      <td>47.000000</td>\n      <td>8.07</td>\n      <td>61.2</td>\n      <td>TACE</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5003</td>\n      <td>0</td>\n      <td>85.544444</td>\n      <td>0</td>\n      <td>1</td>\n      <td>59.76347</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>4.0</td>\n      <td>...</td>\n      <td>21.5</td>\n      <td>58.614578</td>\n      <td>23.4</td>\n      <td>37.0</td>\n      <td>1.155444</td>\n      <td>7.500000</td>\n      <td>87.000000</td>\n      <td>75.00</td>\n      <td>157.0</td>\n      <td>TACE</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5004</td>\n      <td>0</td>\n      <td>1.666573</td>\n      <td>0</td>\n      <td>1</td>\n      <td>58.95445</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>9.8</td>\n      <td>...</td>\n      <td>28.1</td>\n      <td>95.000000</td>\n      <td>306.5</td>\n      <td>118.0</td>\n      <td>1.170000</td>\n      <td>4.600000</td>\n      <td>52.300000</td>\n      <td>62.00</td>\n      <td>131.0</td>\n      <td>TACE</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5005</td>\n      <td>1</td>\n      <td>42.652778</td>\n      <td>0</td>\n      <td>1</td>\n      <td>68.12717</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>4.1</td>\n      <td>...</td>\n      <td>15.9</td>\n      <td>44.000000</td>\n      <td>13.8</td>\n      <td>115.0</td>\n      <td>1.260000</td>\n      <td>5.200000</td>\n      <td>73.088394</td>\n      <td>29.00</td>\n      <td>134.0</td>\n      <td>TACE</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5006</td>\n      <td>0</td>\n      <td>12.486111</td>\n      <td>0</td>\n      <td>1</td>\n      <td>54.56005</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>4.1</td>\n      <td>...</td>\n      <td>34.5</td>\n      <td>24.000000</td>\n      <td>39.0</td>\n      <td>165.0</td>\n      <td>1.140000</td>\n      <td>5.556726</td>\n      <td>73.088394</td>\n      <td>20.90</td>\n      <td>148.5</td>\n      <td>TACE</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 22 columns</p>\n</div>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from config import config\n",
    "\n",
    "# Reading the raw dataset\n",
    "raw_dataset = pd.read_csv(config['path_raw'] + 'TACE_LR.csv')\n",
    "print(\"The raw_dataset has the following shape: {}.\".format(raw_dataset.shape))\n",
    "raw_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset contains 0 null values\n",
      "[316, 318, 339, 366, 389, 525, 605, 661, 664, 720, 723, 768, 780, 781, 786, 845, 852, 859, 864, 1215, 1298, 1302, 1304, 1313, 1317, 1396, 1401, 1408, 1410, 1498, 1501, 1503, 1505, 1511, 1608, 1624, 1628, 1742, 1749, 1894, 1897, 1901, 1904, 1908, 2019, 2022, 2157, 2167, 2178, 2184, 2350, 2352, 2483, 2502, 2513, 2518, 2882, 2891, 3106, 3114, 3355, 3358, 3362, 3378, 3577, 3741, 3751, 3760, 3765, 3917, 3922, 3932, 4069, 4089, 4264, 4266, 4407, 4412, 4420, 4721, 4805, 5042]\n",
      "The dataset contains 82 duplicates\n"
     ]
    }
   ],
   "source": [
    "# Defining the time and event column\n",
    "time_column = 'time'\n",
    "event_column = 'state'\n",
    "\n",
    "# encode, drop...\n",
    "import math\n",
    "raw_dataset['time'] = raw_dataset['time'].apply(lambda x: math.ceil(x))\n",
    "raw_dataset['therapy'] = raw_dataset['therapy'].apply(lambda x: 0 if x == \"TACE\" else 1)\n",
    "raw_dataset['state'] = raw_dataset['state'].apply(lambda x: False if x == 0 else True)\n",
    "dataset = raw_dataset.drop(['ID'], axis=1)\n",
    "dataset_with_id = raw_dataset\n",
    "\n",
    "# Defining the modeling features\n",
    "features_all = np.setdiff1d(dataset.columns, ['time', 'state']).tolist()\n",
    "features_select = [\"tumor_size\",\"therapy\", \"AFP\", \"AST\", \"tumor_number\", \"ECOG\", \"ALB\", \"HGB\", \"INR\"]\n",
    "\n",
    "# Checking for null values\n",
    "N_null = sum(dataset[features_all].isnull().sum())\n",
    "print(\"The dataset contains {} null values\".format(N_null)) #0 null values\n",
    "\n",
    "# Removing duplicates if there exist\n",
    "N_dupli = sum(dataset.duplicated(keep='first'))\n",
    "N_dupli_list = dataset.index[dataset.duplicated(keep='first') == True].tolist()\n",
    "print(N_dupli_list)\n",
    "dataset = dataset.drop_duplicates(keep='first').reset_index(drop=True)\n",
    "dataset_with_id = dataset_with_id.drop(N_dupli_list, axis=0).reset_index(drop=True)\n",
    "print(\"The dataset contains {} duplicates\".format(N_dupli))\n",
    "\n",
    "dataset_x = dataset_with_id[features_all]\n",
    "dataset_y = dataset_with_id[[\"state\", \"time\"]].to_records(index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "dataset_x, dataset_y, test_size=config['valid_ratio'], random_state=config['seed'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The X_train has the following shape: (4192, 19).\n",
      "The X_test has the following shape: (799, 19).\n",
      "The y_train has the following shape: (4192,).\n",
      "The y_test has the following shape: (799,).\n"
     ]
    }
   ],
   "source": [
    "print(\"The X_train has the following shape: {}.\".format(X_train.shape))\n",
    "print(\"The X_test has the following shape: {}.\".format(X_test.shape))\n",
    "print(\"The y_train has the following shape: {}.\".format(y_train.shape))\n",
    "print(\"The y_test has the following shape: {}.\".format(y_test.shape))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training set score is: 0.721144247296369\n",
      "The test set score is: 0.7443302951105849\n"
     ]
    }
   ],
   "source": [
    "from sksurv.ensemble import ComponentwiseGradientBoostingSurvivalAnalysis\n",
    "cgb = ComponentwiseGradientBoostingSurvivalAnalysis(loss=\"coxph\").fit(X_train, y_train)\n",
    "print(\"The training set score is: {}\".format(cgb.score(X_train, y_train)))\n",
    "print(\"The test set score is: {}\".format(cgb.score(X_test, y_test)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training set score is: 0.7305692237713775\n",
      "The test set score is: 0.7534549960120192\n"
     ]
    }
   ],
   "source": [
    "from sksurv.linear_model import CoxPHSurvivalAnalysis\n",
    "coxph = CoxPHSurvivalAnalysis().fit(X_train, y_train)\n",
    "print(\"The training set score is: {}\".format(coxph.score(X_train, y_train)))\n",
    "print(\"The test set score is: {}\".format(coxph.score(X_test, y_test)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training set score is: 0.7652051337806065\n",
      "The test set score is: 0.7601618267460584\n"
     ]
    }
   ],
   "source": [
    "from sksurv.ensemble import GradientBoostingSurvivalAnalysis\n",
    "gb = GradientBoostingSurvivalAnalysis(loss=\"coxph\").fit(X_train, y_train)\n",
    "print(\"The training set score is: {}\".format(gb.score(X_train, y_train)))\n",
    "print(\"The test set score is: {}\".format(gb.score(X_test, y_test)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training set score is: 0.8224906079038695\n",
      "The test set score is: 0.7525370079609127\n"
     ]
    }
   ],
   "source": [
    "from sksurv.ensemble import ExtraSurvivalTrees\n",
    "est = ExtraSurvivalTrees().fit(X_train, y_train)\n",
    "print(\"The training set score is: {}\".format(est.score(X_train, y_train)))\n",
    "print(\"The test set score is: {}\".format(est.score(X_test, y_test)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training set score is: 0.9183335148504218\n",
      "The test set score is: 0.919540604668195\n"
     ]
    }
   ],
   "source": [
    "from sksurv.ensemble import RandomSurvivalForest\n",
    "estimator = RandomSurvivalForest().fit(dataset_x, dataset_y)\n",
    "print(\"The training set score is: {}\".format(estimator.score(X_train, y_train)))\n",
    "print(\"The test set score is: {}\".format(estimator.score(X_test, y_test)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "# read the data\n",
    "train = pd.read_csv(config[\"path_ok\"] + \"data_train.csv\")\n",
    "test = pd.read_csv(config[\"path_ok\"] + \"data_test.csv\")\n",
    "\n",
    "# encode, drop...\n",
    "train['time'] = train['time'].apply(lambda x: math.ceil(x))\n",
    "test['time'] = test['time'].apply(lambda x: math.ceil(x))\n",
    "train['therapy'] = train['therapy'].apply(lambda x: 0 if x == 'TACE' else 1)\n",
    "test['therapy'] = test['therapy'].apply(lambda x: 0 if x == 'TACE' else 1)\n",
    "# train['therapy'] = train['therapy'].apply(lambda x: 1 if x == 'TACE' else 0)\n",
    "# test['therapy'] = test['therapy'].apply(lambda x: 1 if x == 'TACE' else 0)\n",
    "\n",
    "# Defining the modeling features\n",
    "features_all = np.setdiff1d(train.columns, ['time', 'state', 'ID']).tolist()\n",
    "\n",
    "X_train, X_test = train[features_all], test[features_all]\n",
    "T_train, T_test = train[time_column], test[time_column]\n",
    "E_train, E_test = train[event_column], test[event_column]\n",
    "\n",
    "prs = estimator.predict_survival_function(X_train, True)\n",
    "prs_test = estimator.predict_survival_function(X_test, True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "train = pd.read_csv(config[\"path_ok\"] + \"data_train.csv\")\n",
    "test = pd.read_csv(config[\"path_ok\"] + \"data_test.csv\")\n",
    "\n",
    "# concat prs\n",
    "train_rsf = pd.concat([train, pd.DataFrame(prs)], axis=1)\n",
    "test_rsf = pd.concat([test, pd.DataFrame(prs_test)], axis=1)\n",
    "\n",
    "# concat time and event\n",
    "from utils import *\n",
    "v = 0.5\n",
    "\n",
    "# 找到每一个样本的中位生存时间\n",
    "time = []\n",
    "for i in range(train.shape[0]):\n",
    "    middle_day = prs[i].tolist().index(find_nearest(prs[i], v))\n",
    "    time.append(middle_day)\n",
    "train_rsf['pred_time'] = time\n",
    "train_rsf['pred_state'] = 1\n",
    "\n",
    "time = []\n",
    "for i in range(test.shape[0]):\n",
    "    middle_day = prs_test[i].tolist().index(find_nearest(prs_test[i], v))\n",
    "    time.append(middle_day)\n",
    "test_rsf['pred_time'] = time\n",
    "test_rsf['pred_state'] = 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "# save the result\n",
    "train_rsf.to_csv('./data/'+ \"RSF_train_before.csv\", index=False)\n",
    "test_rsf.to_csv('./data/' + \"RSF_test_before.csv\", index=False)\n",
    "# train_rsf.to_csv('./data/'+ \"RSF_train_after.csv\", index=False)\n",
    "# test_rsf.to_csv('./data/' + \"RSF_test_after.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "tumor_size          0.669369\ntherapy             0.633784\nAFP                 0.610519\nAST                 0.599039\ntumor_number        0.594154\nECOG                0.573752\nALB                 0.570808\nHGB                 0.560430\nINR                 0.555996\nWBC                 0.542874\nBUN                 0.537982\nALT                 0.530191\nTBIL                0.514794\ntreatment_before    0.511717\nCr                  0.509072\nEtiology            0.508923\nPLT                 0.506582\ngender              0.505376\nage                 0.500892\ndtype: float64"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def fit_and_score_features(X, y):\n",
    "    n_features = X.shape[1]\n",
    "    scores = np.empty(n_features)\n",
    "    m = coxph\n",
    "    for j in range(n_features):\n",
    "        Xj = X[:, j:j+1]\n",
    "        m.fit(Xj, y)\n",
    "        scores[j] = m.score(Xj, y)\n",
    "    return scores\n",
    "\n",
    "sc = fit_and_score_features(dataset_x.values, dataset_y)\n",
    "pd.Series(sc, index=dataset_x.columns).sort_values(ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sksurv.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "\n",
    "pipe = Pipeline([('encode', OneHotEncoder()),\n",
    "                 ('select', SelectKBest(fit_and_score_features, k=3)),\n",
    "                 ('model', coxph)])\n",
    "param_grid = {'select__k': np.arange(1, dataset_x.shape[1] + 1)}\n",
    "cv = KFold(n_splits=3, random_state=42, shuffle=True)\n",
    "gcv = GridSearchCV(pipe, param_grid, return_train_score=True, cv=cv)\n",
    "gcv.fit(dataset_x, dataset_y)\n",
    "\n",
    "results = pd.DataFrame(gcv.cv_results_).sort_values(by='mean_test_score', ascending=False)\n",
    "results.loc[:, ~results.columns.str.endswith(\"_time\")]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}